{"cells":[{"cell_type":"code","source":["import cv2\n\nimport pyspark.sql.functions as f\nfrom pyspark.sql.types import *\n\nimport numpy as npa\n\nimport pandas as pd\nimport random\n\n\nfrom sklearn.mixture import BayesianGaussianMixture"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"755c524c-89cd-4c57-b16a-83aa70a251cc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##### Notebook Classes (Fixed Rotation): \n- ###### SampleData \n  - class that stores data for Neural Network Models \n  - Attributes: \n              Data = data used to create instance (can be either np.ndarray or dict)\n\n| Functions        | Arguments      |Description|\n| -----------------| -------------- |-----------|\n| **len**    | self         |returns number of samples in dataset          |\n| **getitem**  | self, position        |returns data at specific posistion            |\n| **keys**| self         |if data is of type dictionary, return distinct keys          |\n| **values**| self         |if data is of type dictionary, returns list of all values in given dictionary |\n| **items**| self         |if data is of type dictionary, returns key-value pairs as tuples in a list           |\n| **get_random_index**| self, index, train_test (?)         |randomly generates an index from the dictionary |\n| **get_data_as_list**| self         |returns dictionary data as a list to feed into models           |\n\n\n\n- ###### GameLabels \n  - class that creates label/title that will be displayed with model results/heatmaps\n  - Attributes: \n              label_columns = desired columns, \n              required_cols = required columns in table\n\n| Functions        | Arguments      |Description|\n| -----------------| -------------- |-----------|\n| **validate**     | self, obj         |verifys that required columns are in the table, if not error with missing required column returned         |\n| **complete_labels**              | self, maps        |returns teamNames, defenseNames, gcStart/End columns by mapping teamName and defenseName to the affiliated teams and also converting gcTime from total seconds to minutes format           |\n| **get_row_labels**   | self, index         |returns row @ specified index with all of the columns in label_cols            |\n| **get_row_title**   | self, title, long         | returns title (for heatmaps) that displays gameId, offensive/defensive team names, current period and gcTime  (NOT sure what long means in this context)   |\n\n\n\n\n\n- ###### SampleDataSet \n  - Class that helps build model and sample latent space for similar plays\n  - Attributes: \n                X_train, X_training_labels, X_test, X_test_labels = Training/Testing data + labels,\n                X_hat_train, X_hat_test = predictions,  \n                z_train, z_test = latent space activations, \n                z_train_prob, z_test_prob = posterior probabilities \n\n| Functions        | Arguments                               |Description|\n| -----------------| ---------------------------- -----------|-----------|\n| **emit_data**    |self                                     |returns X_training data + labels and X_testing data and labels     |\n| **add_predictions** |self, model_obj                       |returns predictions for training and testing data (X_hat_train/test), the latent space activations (z_train/test), and posterior probability of latent space activation (z_train/test_prob)|\n| **get_candidates** |self, latent_dim, n_neighbours, n_sets |returns candidate games/plays that are in close proximity to each other|\n| **candidate_set_to_table** |self, candidate_set, save_path |returns corresponding rows/data based on selected candidates and saves output as table          |\n\n\n- ###### ModelData\n - Class to generate dataset for models\n - Attributes: \n              experiment_name = experiment name,\n              model_name = model name, \n              image_size = image size, \n              new_dividers = bool for whether new dividers are being used, \n              database_name = database name,\n              h_rank = used for seed value, \n              flat = bool for whether data will be reshaped (image vs flat vector), \n              train_data_table = training set, \n              test_data_table = testing set,\n              train_test_split = breakdown of what percent of data will be reserved for training/testing, \n              \n\n| Functions        | Arguments      |Description|\n| -----------------| -------------- |-----------|\n| **generate_maps** |self           |creating maps for teamNames, teamIds, and gameIds         |\n| **get_divider_maps**|self, df_heatmaps|returns map start and end times based on divider start/end times           |\n| **write_data_to_table**|self          |merges previously generated tables (position, ball position, team latitude and team longitude), splits data into training and testing sets, samples and saves output             |\n| **get_dataset** |self          |returns training and testing data + labels from the dataset           |\n| **resize_courts** |self, df_heatmaps_pandas, col_name          |resizes heatmap images    |\n| **cleanup_data** |self          |drops training and testing tables|"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f01c378c-18ee-45f0-8d20-41e4804e4d8f"}}},{"cell_type":"code","source":["class SampleData:\n  '''\n  A class to store the data for the Neural Network models\n\n  ...\n\n  Attributes\n  ----------\n  - data - the data used to create the instance\n    - May be either a np.ndarray or dict\n\n  Methods\n  -------\n   - __len__ - Gets the number of samples in the data\n   - __getitem__ - Used to access a sample of the data in a consistent way\n   - split_kwargs - Splits a dictionary (kwargs) in to two dictionaries according to if the key is present in a list (args_list) \n   - get_random_index - return an index within the range of the data\n   - get_data_as_list - return the data (dictionary) as a list ready to feed to a many-headed Neural Network\n  '''\n  def __init__(self, data):\n    \n    assert(type(data)) in [dict, np.ndarray]\n    \n    self.data = data\n    \n  def __len__(self):\n    if type(self.data) is dict:\n      xx = list(self.data.values())[0]\n    else:\n      xx = self.data\n    \n    #assert max(xx.shape) == xx.shape[0]\n    return xx.shape[0]\n    \n  def __getitem__(self, position):\n    return self.data[position]\n  \n  def keys(self):\n    #doesn't work, probably not used in pipeline, should be self.data\n    if type(data) is dict:\n      return self.data.keys()\n    else:\n      return None\n  \n  def values(self):\n    #doesn't work, probably not used in pipeline, should be self.data\n    if type(data) is dict:\n      return self.data.values()\n    else:\n      return None\n  \n  def items(self):\n    #doesn't work, probably not used in pipeline, should be self.data\n    if type(data) is dict:\n      return self.data.items()\n    else:\n      return None\n  #def get_model_data(self):\n  #  return [x for x in self.data.values]\n  \n  def get_random_index(self, index, train_test='test'):\n    if index is None:\n      return np.random.randint(self.__len__())\n    else:\n      return index\n  \n  def get_data_as_list(self):\n    return [x for x in self.data.values()]\n    \n  \n@pd.api.extensions.register_dataframe_accessor(\"GameLabels\")\nclass GameLabels:\n  \n  def __init__(self, pandas_obj):\n    \n\n    self.label_cols = ['gameId', 'dividerId', 'teamId', 'teamName', 'defenceName', 'startGcTime', 'endGcTime', 'startWcTime', 'endWcTime', 'period']\n\n    \n    self.required_cols = ['gameId', 'teamId', 'startWcTime', 'endWcTime', 'startGcTime', 'endGcTime', 'period']\n    self._validate(pandas_obj)\n    self._obj = pandas_obj\n\n  def _validate(self, obj):\n    # verify there is a column latitude and a column longitude\n    for col_name in self.required_cols:\n      if col_name not in obj.columns:\n        raise AttributeError(f\"Must have '{col_name}'.\")\n      \n  def complete_labels(self, maps):\n    self._obj[\"teamName\"] = self._obj[\"teamId\"].apply(lambda team_id: maps['team_name_mapping_dict'][team_id])\n    self._obj[\"defenceName\"] = self._obj.apply(\\\n                                 lambda row: [ maps['team_name_mapping_dict'][x] \n                                                 for x in maps['game_mapping_dict'][row['gameId']] \n                                                 if x != row['teamId']][0], axis=1 )\n    \n    #self._obj[\"startWcTime\"] = self._obj[\"startWcTime\"].astype(int).apply(lambda x: f\"{x//60:02d}:{x%60:02d}\")\n    #self._obj[\"endWcTime\"] = self._obj[\"endWcTime\"].astype(int).apply(lambda x: f\"{x//60:02d}:{x%60:02d}\")\n    \n    self._obj[\"startGcTime\"] = self._obj[\"startGcTime\"].astype(int).apply(lambda x: f\"{x//60:02d}:{x%60:02d}\")\n    self._obj[\"endGcTime\"] = self._obj[\"endGcTime\"].astype(int).apply(lambda x: f\"{x//60:02d}:{x%60:02d}\")\n      \n  def get_row_labels(self, index):\n    return self._obj.loc[index, self.label_cols]\n  \n  #TODO: Mrinal, the below had to be added so that the 'load' approach could also get row labels\n  def get_row_labels_alt(self, index, cols):\n    return self._obj.loc[index, cols]\n\n  def get_row_title(self, index, title='Original', long=True):\n    \n    game_id, dividerId, team_id, team_name, defence_name, gc_start_time, gc_end_time, wc_start_time, wc_end_time, period = self.get_row_labels(index)\n    \n    if long:\n      return \\\n      f'''{title} GameId: {game_id}; DividerId: {dividerId}, TeamId: {team_name} [hp] vs {defence_name}\n      Time (P-{period}): {gc_start_time} - {gc_end_time}'''\n    else:\n      r_str = f\"GameId: {game_id}\\nDividerId: {dividerId}\\nOffence: {team_name}\\nDefence: {defence_name}\\nPeriod {period}\\n\"\n      r_str += f\"Start GC: {gc_start_time}\\nEnd GC: {gc_end_time}\"\n      return r_str"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9aa59da4-90d6-4189-8d79-f1049df4fb77"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["class SampleDataSet:\n  def __init__(self, X_train, X_train_labels, X_test, X_test_labels, maps, col_names, building_model_data = True):\n    self.col_names = col_names\n    \n    self.X_train = SampleData(X_train)\n    self.X_train_labels = X_train_labels.copy()#, maps)\n    self.X_test = SampleData(X_test)\n    self.X_test_labels = X_test_labels.copy()#, maps)\n    \n    self.X_train_labels.GameLabels.complete_labels(maps)\n    self.X_test_labels.GameLabels.complete_labels(maps)\n    \n    self.X_hat_train = None\n    self.X_hat_test = None\n    \n    self.z_train = None\n    self.z_test = None\n    \n    self.z_train_prob = None\n    self.z_test_prob = None\n    \n  def emit_data(self):\n    return (self.X_train, self.X_train_labels), (self.X_test, self.X_test_labels)\n  \n  def add_predictions(self, model_obj):\n    self.x_ = self.X_train.get_data_as_list()\n    self.X_hat_train = SampleData(dict(zip(self.col_names, model_obj.predict(self.x_))))\n    self.z_train = model_obj.encoder.predict(self.x_)\n    \n    bgm = BayesianGaussianMixture(n_components=1, random_state=42).fit(self.z_train)\n    self.z_train_prob = np.exp(bgm.score_samples(self.z_train))\n    \n    self.x_ = self.X_test.get_data_as_list()\n    self.X_hat_test = SampleData(dict(zip(self.col_names, model_obj.predict(self.x_))))\n    self.z_test = model_obj.encoder.predict(self.x_)\n    \n    bgm = BayesianGaussianMixture(n_components=1, random_state=42).fit(self.z_test)\n    self.z_test_prob = np.exp(bgm.score_samples(self.z_test))\n    \n  def get_candidates(self, latent_dim, n_neighbours=10, n_sets=20):\n    base_nline = np.array([ -0.3, -0.15, 0.0, 0,15, 0.3 ])\n\n    n = len(base_nline)\n\n    total_coords = n ** latent_dim\n    limit_coords = min(n_sets, total_coords)\n\n    if total_coords > 10 ** 4:\n      rand_i = np.random.randint(0, total_coords, limit_coords, dtype=np.long)\n    else:\n      rand_i = np.random.choice(range(total_coords), limit_coords, replace=False)\n\n    all_coords = [ base_nline[i // (  n ** np.arange(latent_dim) ) % n] for i in rand_i]\n\n    candidate_sets = []\n    for v in all_coords:\n      v = v.reshape(1, latent_dim)\n      d = ((self.z_test - v) ** 2).sum(1)\n      dx = np.argsort(d)\n      cent = dx[0]\n      neighbours = dx[1:n_neighbours+1]\n      candidate_sets.append({\"grid_coords\": v,\n                             \"cent_dx\": cent,\n                             \"cent_coods\": self.z_test[cent,:],\n                             \"neigh_dx\": neighbours,\n                             \"neigh_coords\": self.z_test[neighbours,:]})\n      \n    return candidate_sets\n    \n  def candidate_set_to_table(self, candidate_set, save_path=None):\n    n = len(candidate_set['neigh_dx'])\n    c_df = self.X_test_labels.GameLabels.get_row_labels([candidate_set[\"cent_dx\"]])\n    n_df = self.X_test_labels.GameLabels.get_row_labels(candidate_set[\"neigh_dx\"])\n    df_candidates = pd.concat([c_df, n_df])\n\n    df_candidates.loc[:, \"is_center\"] = [True] + [False] * n\n    df_candidates.loc[:, \"index\"] = [candidate_set[\"cent_dx\"]] + list(candidate_set[\"neigh_dx\"])\n    \n    if save_path:\n      #f\"/dbfs/FileStore/gb-cache/experiments/{settings['experiment_name']}/{settings['model_name']}/candidates/candidates_{q}.csv\"\n      df_candidates.to_csv(save_path, index=False)\n    \n    return df_candidates\n  \n\nclass ModelData:\n  def __init__(self, experiment_name, image_size=(28,28), flat=True, new_dividers=False, database_name=\"default\", h_rank=0, quick_run = False, forced_test_list = None, v2 = False, additional_label = None, expbh = False, chiral = False, chiral_list = None):\n    \n    #ModelData will take in the raw heatmaps generated by Generate Heatmaps notebook, rescale, reorganize, make a test and train split, assure forced list is in test set, and finally outputs that test and train into a specifc location\n    \n    #  Input from heatmaps:\n    #  (position table) gameId, dividerId, [[court]]\n    #  (v2 table) gameId, dividerId, [[court]]\n    #  (ball table) gameId, dividerId, [[court]]\n    #       -----> INIT modelData --->\n    #  gameId, dividerId, [[position (normalized)]], [[v2 (normalized)]], [[ball (normalized)]]   \n    # split into train and test sets and written to tables\n    \n    self.experiment_name = experiment_name\n    #self.model_name = model_name\n    self.image_size = image_size\n    self.new_dividers = new_dividers\n    self.database_name = database_name\n    self.h_rank = h_rank\n    self.flat = flat\n    #Below is the manually labeled dividerIds that we want to be sure are in test set \n    self.forced_test_list = forced_test_list\n    self.quick_run = quick_run\n    #Type of experiment or heatmaps included\n    self.v2 = v2\n    self.expbh = expbh\n    self.chiral = chiral\n    self.chiral_list = chiral_list\n    \n    #JF Where the train and test tables will be written out to\n    self.train_data_table = f\"default.{self.experiment_name}_train\" #_{self.model_name}\n    self.test_data_table = f\"default.{self.experiment_name}_test\" #_{self.model_name}\n    \n    #JF spliting ratio hardcoded\n    self.train_test_split = [0.7, 0.3]\n    \n    if additional_label:\n      additional_label = '_' + additional_label\n    else:\n      additional_label = ''\n      \n      \n    #The below should be rewritten to accomidate any combination of desired heatmaps, instead of specific combinations only\n    #It is currently written according to the layout found in Generate Heatmaps, i.e. the \"v2\" experiment or the \"expbh\" experiment\n    \n    if self.v2:\n      print(f'v2 turned on: {self.v2}')\n      self.base_table_name = (\"new_play_v2_positionmaps\" + additional_label, \"position\")\n      self.table_names = {\"new_play_v2_velocitymaps\" + additional_label: \"v2\", \n                          \"new_play_v2_positionball\" + additional_label: \"ball\"}\n    #JF Only using new dividers now.  These are the locations where Heatmap Generation by DividerId places the heatmaps\n    #Why is one of these a tuple and the other a dict?\n    \n    elif self.expbh:\n      print(f'expbh turned on: {self.expbh}')\n      self.base_table_name = (\"new_play_positionmaps\" + additional_label, \"position\")\n      self.table_names = {\"new_play_velocitymaps_dx\" + additional_label: \"dx\", \n                          \"new_play_velocitymaps_dy\" + additional_label: \"dy\", \n                          \"new_play_expbh\" + additional_label: \"expbh\", \n                          \"new_play_positionball\" + additional_label: \"ball\"}\n    \n    elif self.new_dividers:\n      self.base_table_name = (\"new_play_positionmaps\" + additional_label, \"position\")\n      self.table_names = {\"new_play_velocitymaps_dx\" + additional_label: \"dx\", \n                          \"new_play_velocitymaps_dy\" + additional_label: \"dy\", \n                          \"new_play_positionball\" + additional_label: \"ball\"}\n    else:\n      self.base_table_name = (\"play_positionmaps\", \"position\")\n      self.table_names = {\"play_velocitymaps_dx\": \"dx\", \n                          \"play_velocitymaps_dy\": \"dy\", \n                          \"play_positionball\": \"ball\"}\n      \n    self.col_names = [self.base_table_name[1]] + list(self.table_names.values())\n    \n    #The below does a lot more than write to table\n    self.write_data_to_table(v2 = self.v2, expbh = self.expbh)\n    \n    self.generate_maps()\n    \n  \n    \n  def generate_maps(self):\n    #PART OF INIT\n    self.maps = {}\n    \n    self.maps['team_name_mapping_dict'] = \\\n      {\n        x.nbaId: x.name for x in \n          spark.read.parquet(\"/mnt/blob-storage/mappings_team.parquet\")\n               .select(\"nbaId\", \"name\")\n               .collect()\n       }\n    \n    self.maps['team_mapping_id_dict'] = \\\n      { \n        x.id: x.nbaId for x in \n          spark.read.parquet(\"/mnt/blob-storage/mappings_team.parquet\")\n               .select(\"nbaId\", \"id\")\n               .collect()\n      }\n    \n    self.maps['game_mapping_dict'] = \\\n      { \n        x.gameId: [self.maps['team_mapping_id_dict'][x.homeTeamId], self.maps['team_mapping_id_dict'][x.awayTeamId]] for x in \n          spark.read.parquet(\"/mnt/blob-storage/mappings_gameid.parquet\")\n               .select(f.col(\"nbaId\").alias(\"gameId\"), \"homeTeamId\", \"awayTeamId\")\n               .collect()\n      }\n\n  def get_divider_maps(self, df_heatmaps):\n    \n    def get_oh_list(k,n):\n      x = [0] * n\n      x[k] = 1\n      return x\n\n    all_starts = df_heatmaps.select([\"StartDivider\"]).distinct().collect()\n    n = len(all_starts)\n    all_starts = {x.StartDivider: get_oh_list(k,n) for k, x in enumerate(all_starts)}\n\n    all_ends = df_heatmaps.select([\"EndDivider\"]).distinct().collect()\n    n = len(all_ends)\n    all_ends = {x.EndDivider: get_oh_list(k,n) for k, x in enumerate(all_ends)}\n\n    map_start = f.udf(lambda start_divider: all_starts[start_divider], ArrayType(IntegerType()))\n    map_end = f.udf(lambda end_divider: all_ends[end_divider], ArrayType(IntegerType()))\n\n    return map_start, map_end\n  \n  def remove_shot_dividers(self, df_heatmaps):\n    #PART OF INIT\n    df_heatmaps = df_heatmaps.filter(f.col('StartDivider') != 'shot taken')\n    return df_heatmaps\n\n\n  def write_data_to_table(self, v2 = False, expbh = False):\n    #PART OF INIT    \n    #BULK OF COMPUTATION OF INIT MODEL_DATA takes place here\n    \n    #UDFs\n    @udf(\"array<float>\")\n    \n    def empty_heatmap():\n      return [float(0.0) for x in np.arange(0,5151)]\n    \n    @udf(\"array<float>\")\n    def add_noise(xs):\n      for i in range(1, len(xs)-1):\n        #adds small amount of positive amplitude to neighboring cells in heatmap\n        if ((xs[i] == 0) & ((xs[i-1] > 0)|(xs[i+1] > 0))):\n          xs[i] = float(np.maximum(0.0, xs[i] + 1./10*(2*random.random() - 1)))  \n        #could cals add noise to the nonzero part, *not sure* if necessary\n      return xs\n    \n    def add_noise_to_dataframe(df, add_noise_to):\n      for column in add_noise_to:\n        df = df.withColumn(column, f.col(column))\n        df = df.withColumn(column, add_noise(column))\n      return df\n    \n    \n    def transfer_games_to_test(forced_test_list, train_df, test_df, v2 = False, expbh = False, noise = True, identicals = True):\n      \n      #function that moves manually annotated games to test set and not the training set\n      forced_test_df_pd = pd.DataFrame(forced_test_list)\n      forced_test_df = spark.createDataFrame(forced_test_df_pd)\n      \n      rows_to_transfer = forced_test_df.alias('forced').join(train_df.alias('train'), (f.col('forced.gameId') == f.col('train.gameId')) \n                                                             & (f.col('forced.dividerId') == f.col('train.dividerId'))).select('train.*')\n      rows_already_there = forced_test_df.alias('forced').join(test_df.alias('test'), (f.col('forced.gameId') == f.col('test.gameId')) \n                                                             & (f.col('forced.dividerId') == f.col('test.dividerId'))).select('test.*')\n\n      print(\"{} subsequenced desired in test set were found in training set\".format(rows_to_transfer.count()))\n      print(\"{} subsequenced desired in test set were already in the test set\".format(rows_already_there.count()))\n\n      resulting_train_df = train_df.alias('train') \\\n        .join(rows_to_transfer.select('gameId', 'dividerId').alias('transfer'), (f.col('transfer.gameId') == f.col('train.gameId')) \\\n                                                                              & (f.col('transfer.dividerId') == f.col('train.dividerId') \\\n                                                                                ), \"left_outer\")\\\n                     .where(f.col('transfer.gameId').isNull()).select('train.*')\n      \n      print(\"{} # of columns in test_df\".format(len(test_df.columns)))\n      print(\"{} columns in test_df\".format(test_df.columns))\n      print(\"{} # of columns in rows_to_transfer\".format(len(rows_to_transfer.columns)))\n      print(\"{} columns in rows_to_transfer\".format(rows_to_transfer.columns))\n      print(\"{} # of columns in rows_already_there\".format(len(rows_already_there.columns)))\n      print(\"{} columns in rows_already_there\".format(rows_already_there.columns))\n      resulting_test_df = test_df.union(rows_to_transfer)\n      \n      both_df = rows_to_transfer.union(rows_already_there)\n      \n      if identicals:\n        both_df = both_df.withColumn('dividerId', f.col('dividerId') + f.lit(10000)) \n        #simplest sanity check that divider id X and divider id 10000 + x are right next to each other  \n        #[gameId:5, dividerId:120] is identical to [gameId:5, dividerId:10120] \n        resulting_test_df = resulting_test_df.union(both_df)\n      \n      if noise:\n\n        if v2:\n          noise_df = add_noise_to_dataframe(both_df, add_noise_to = ['position', 'v2', 'ball'])\n        elif expbh:\n          noise_df = add_noise_to_dataframe(both_df, add_noise_to = ['position', 'dx', 'dy', 'expbh', 'ball'])\n        else:\n          noise_df = add_noise_to_dataframe(both_df, add_noise_to = ['position', 'dx', 'dy', 'ball'])\n          \n        noise_df = noise_df.withColumn('dividerId', f.col('dividerId') + f.lit(20000)) #add 20000 to dividerId\n        #e.g.  [gameId:5, dividerId:120] is the original, and [gameId:5, dividerId:30120] has the noise added to heatmaps according to add_noise_to_dataframe() \n        #TODO check what happens if identical, noise, and chiral are one make seure there isn't a collision between noise: 30XXX(i think) and chiral 20XXX\n        resulting_test_df = resulting_test_df.union(noise_df)\n        \n      #returns the train_df minus the plays in forced_test_list\n      #returns the test_df in additiona to plays in forced_test_list (that were found in train)\n      #and the identical copies of those plays with dividerId 10XXX\n      #and the noise added versions of those plays with dividerId 20XXX\n      #(note that 30XXX is the noise_added version of the identical copies)\n      return resulting_train_df, resulting_test_df, both_df\n        \n    \n    #BODY OF FUNCTION\n    \n    select_columns = [\"gameId\", \"teamId\", \"possId\", \"dividerId\", \"court\"]\n    on_columns = [\"gameId\", \"teamId\", \"possId\", \"dividerId\"]\n    #below might not be needed with new dividerId mapping table\n    #df_poss_basket_map = spark.sql(\"SELECT possId, basketX FROM nba_tracking_data.possessions\").distinct()\n    \n    #Below follows the structure of the written out heatmap tables, e.g.\n      #self.base_table_name = (\"new_play_v2_positionmaps\" + additional_label, \"position\")\n      #self.table_names = {\"new_play_v2_velocitymaps\" + additional_label: \"v2\", \n      #                    \"new_play_v2_positionball\" + additional_label: \"ball\"}\n    \n    #BASE TABLE/HEATMAP (position)\n    if self.quick_run:\n      #quick_run is just to quickly make sure no errors\n      forced_test = tuple(x['gameId'] for x in self.forced_test_list)\n      df_heatmaps = ( spark.sql(f\"SELECT * FROM {self.database_name}.{self.base_table_name[0]} where gameId in {forced_test}\")\n                         .withColumnRenamed(\"court\", self.base_table_name[1]))\n                         #.join(df_poss_basket_map, on='possId', how='left') )\n    else:\n      df_heatmaps = ( spark.sql(f\"SELECT * FROM {self.database_name}.{self.base_table_name[0]}\")\n                         .withColumnRenamed(\"court\", self.base_table_name[1]))\n                         #.join(df_poss_basket_map, on='possId', how='left') )\n      \n    #JF ADD\n    #Remove Play Subsequences that begin with a shot event (ball in air) for base table\n    df_heatmaps = self.remove_shot_dividers(df_heatmaps)    \n    \n    #Displaying nulls for BASE TABLE\n    temp_cols = ['teamId', 'startWcTime', 'endWcTime', 'startGcTime', 'endGcTime', 'period', 'gameId', 'possId', 'dividerId', 'outcome']\n    df_heatmaps.select([f.count(f.when(f.isnan(c), c)).alias(c) for c in temp_cols]).show()\n    df_heatmaps.select([f.count(f.when(f.col(c).isNull(), c)).alias(c) for c in temp_cols]).show()\n    df_heatmaps = df_heatmaps.where(f.col('possId').isNotNull())\n\n    #Scale the heatmaps\n    df_heatmaps = self.scale_court_column(df_heatmaps, self.base_table_name[1])\n    print('Base Table done...')\n    \n                                    \n    #ALL OTHER TABLES/HEATMAPS                                \n    for table_name, new_column_name in self.table_names.items():\n      print(f\"Creating heatmap from {table_name}, for variable {new_column_name}\")\n      \n      if self.quick_run:\n        forced_test = tuple(x['gameId'] for x in self.forced_test_list)\n        df_heatmaps = ( df_heatmaps.join(\n                             spark.sql(f\"SELECT * FROM {self.database_name}.{table_name} where gameId in {forced_test}\")\n                                  .select(select_columns)\n                                  .withColumnRenamed(\"court\", new_column_name), \n                             on=on_columns, how=\"left\") )\n      else:\n        df_heatmaps = ( df_heatmaps.join(\n                             spark.sql(f\"SELECT * FROM {self.database_name}.{table_name}\")\n                                  .select(select_columns)\n                                  .withColumnRenamed(\"court\", new_column_name), \n                             on=on_columns, how=\"left\") )\n      \n      current_null_ratio = float(df_heatmaps.filter(f.col(new_column_name).isNull()).count())/float(df_heatmaps.count() * 100) \n      print(f\"% of missing velocity maps:{current_null_ratio}\")\n      \n      #handling nulls (from left join, velocity maps missing? TODO find them)\n      df_heatmaps = df_heatmaps.withColumn(new_column_name, \n                                           f.when(f.col(new_column_name).isNull(), \n                                                  empty_heatmap()).otherwise(f.col(new_column_name)))\n      \n      current_null_ratio = float(df_heatmaps.filter(f.col(new_column_name).isNull()).count())/float(df_heatmaps.count() * 100)             \n      print(f\"% of missing velocity maps after filling:{current_null_ratio}\")\n      \n      #JF ADD\n      #Removing shot dividers for all other tables (this shouldn't be needed as left join from base table which had these removed)\n      df_heatmaps = self.remove_shot_dividers(df_heatmaps)\n      \n      temp_cols = ['teamId', 'startWcTime', 'endWcTime', 'startGcTime', 'endGcTime', 'period', 'gameId', 'possId', 'dividerId', 'outcome']\n      # displaying nulls for ALL OTHER TABLES\n      df_heatmaps.select([f.count(f.when(f.isnan(c), c)).alias(c) for c in temp_cols]).show()\n      df_heatmaps.select([f.count(f.when(f.col(c).isNull(), c)).alias(c) for c in temp_cols]).show()\n      df_heatmaps = df_heatmaps.where(f.col('possId').isNotNull())\n\n      #Scale the heatmaps\n      df_heatmaps = self.scale_court_column(df_heatmaps, new_column_name)      \n      print(\"Table: {} done...\".format(table_name))\n\n          \n    map_start, map_end = self.get_divider_maps(df_heatmaps)\n\n    #TODO: This shouldn't be needed as reason for new subsequence and end of subsequence come with df_preprocessed along with divider Id\n    df_heatmaps = ( df_heatmaps.withColumn(\"StartDividerOH\", map_start(\"StartDivider\"))\n                               .withColumn(\"EndDividerOH\", map_end(\"EndDivider\")) )\n\n#     df_fta = spark.sql(\"SELECT possId, fta FROM nba_tracking_data.possessions\")\n\n#     df_heatmaps = df_heatmaps.join(df_fta, on=\"possId\", how='left')\n\n    df_heatmaps = ( df_heatmaps.filter(f.col(\"hasPoss\") == True)\n                               .filter(f.col(\"fta\") == 0)\n                               .filter(f.col(\"dividerId\").isNull() == False) )\n    \n    #JF Here is where it is decided which data will be train and which will be test\n    #After this would be a perfect spot to ensure that the subsequences you want to test are not in the train set, and are instead in the test set\n    #But we need to make sure that every object upstream of this data reflects the change\n    df_train, df_test = df_heatmaps.randomSplit(self.train_test_split, seed=42)\n    print('# of train columns {}', format(len(df_train.columns)))\n    print('# of test columns {}',format(len(df_test.columns)))\n    print('train columns {}',format(df_train.columns))\n    print('test columns {}',format(df_test.columns))\n  \n    #Switch em to test \n    if self.forced_test_list:\n        df_train, df_test, both_df = transfer_games_to_test(self.forced_test_list, df_train, df_test, v2 = v2, expbh = expbh)\n    \n    if self.chiral:\n        df_train, df_test, both_df = transfer_games_to_test(self.chiral_list, df_train, df_test, v2 = v2, expbh = expbh, noise = False, identicals = False)\n\n    #TRAIN AND TEST SET WRITTEN OUT\n    df_train.write.mode(\"overwrite\").saveAsTable(self.train_data_table)\n    df_test.write.mode(\"overwrite\").saveAsTable(self.test_data_table)\n\n#     if self.forced_test_list or self.chiral:\n#       return df_train, df_test, both_df    \n#     else:\n#       return df_train, df_test  \n\n  @staticmethod\n  def scale_court_column(df_heatmaps, col_name):\n        \n    print('SCALING COURT for: {}'.format(col_name))\n  \n    def get_min_max(df_heatmaps, col_name):\n      udf_max = f.udf(lambda x: float(np.max(x)), FloatType())\n      udf_min = f.udf(lambda x: float(np.min(x)), FloatType())\n    \n      df_heatmaps = ( df_heatmaps.withColumn(\"positionMax\", udf_max(col_name))\n                                 .withColumn(\"positionMin\", udf_min(col_name)) )\n\n      min_max = df_heatmaps.agg(f.max(\"positionMax\").alias(\"posMax\"),\n                                f.min(\"positionMin\").alias(\"posMin\")).collect()[0]\n      x_min = min_max.posMin\n      x_max = min_max.posMax\n\n      df_heatmaps = df_heatmaps.drop(\"positionMax\").drop(\"positionMin\")#, f.col()])\n\n      #assert x_min == 0\n\n      return x_min, x_max\n\n    x_min, x_max = get_min_max(df_heatmaps, col_name)\n    print(f\"{col_name} [Original Scale]: {x_min} -- {x_max}\")\n\n    udf_scaler = f.udf(lambda x_list: \n                         [ float(np.log( x + 1 ) / np.log( x_max + 1 )) for x in x_list ], \n                         ArrayType(FloatType()))\n\n    df_heatmaps = df_heatmaps.withColumn(col_name, udf_scaler(col_name))\n\n    x_min, x_max = get_min_max(df_heatmaps, col_name)\n    print(f\"{col_name} [Scaled]: {x_min} -- {x_max}\")\n\n    return df_heatmaps\n    \n  def get_dataset(self):\n    \n    #?JF: Why are we only sampling 40% of our datasets?\n\n    \n    df_train_pandas = ( spark.sql(f\"SELECT * FROM {self.train_data_table}\").toPandas())\n                             #.sample(0.4, seed=self.h_rank).toPandas() )\n    df_test_pandas = ( spark.sql(f\"SELECT * FROM {self.test_data_table}\").toPandas())\n                             #.sample(0.4, seed=self.h_rank).toPandas() )\n\n    X_train = {}\n    X_test = {}\n    \n    print(\"Inside get_dataset, self.col_names {}\".format(self.col_names))\n    for col_name in self.col_names:\n      print(\"Inside get_dataset, working on {}\".format(col_name))\n      X_train[col_name], X_train_labels = self.resize_courts(df_train_pandas, col_name)\n      X_test[col_name], X_test_labels = self.resize_courts(df_test_pandas, col_name)\n\n    #return X_train, X_train_labels, X_test, X_test_labels\n      \n    self.sample_data = SampleDataSet(X_train, X_train_labels, X_test, X_test_labels, self.maps, self.col_names)\n      \n    return self.sample_data.emit_data()\n\n\n  \n  def resize_courts(self, df_heatmaps_pandas, col_name, already_reoriented = False):\n      \n    #This thing basically cuts the court in half, and spins it around so all offensive courts are oriented in the same way. \n    #Again, this is coded in an obtuse way, and should be refactored to be human readable.\n\n    #we'll need a new option in here for velocity phase space maps, to be warped to fit the same image, instead of just cut in half.  \n    #this could be done up where v2 velocity gets scaled.  We could just fit it to image size right then.\n    \n    \n    print(f\"resizing for {col_name}\")\n    X = np.array(df_heatmaps_pandas[col_name].apply(lambda x: x.reshape(101,51)).tolist())\n    print(X.shape)\n    basketX = list(df_heatmaps_pandas[\"basketX\"])\n    \n    \n    # Starting with a column chosed from e.g. ['position', 'v2', 'ball]\n    # [gameId-dividerId index, x_grid bin, y grid bin]\n    # And then we'll need to only pick the half court we are interested in.\n    # if we've previously reoriented by basketX in the heatmaps notebook, then this is simple.\n    # (note v2 is different check out note above)\n    Xi = np.zeros([X.shape[0], 51, 51])\n    for c in range(X.shape[0]):\n      xi = X[c,:,:]\n      #if xi[:51,:].sum() > xi[50:,:].sum():\n      \n      if already_reoriented:\n        if col_name == 'v2':\n          Xi[c,:,:] = xi[25:76,:]\n            \n        else:\n          Xi[c,:,:] = xi[:51,:]\n        \n        \n      else:\n        if col_name == 'v2':\n          #print(\"Different cut used for v2\")\n          if basketX[c] < 0:\n            Xi[c,:,:] = xi[25:76,:]\n          #TODO: BELOW IS WRONG Original error: pretty sure the below is a relfection for x coordinate, and not a rotation about z axis\n          #still using it because of memory errors with the solution\n          else:\n            Xi[c,:,:] = xi[25:76,:][::-1]\n          # THE BELOW IS CORRECT\n  #         else:\n  #           print('New Rotation')\n  #           Xi[c,:,:] = np.array([x[::-1] for x in xi[25:76,:][::-1]])\n\n        else:\n          #print(\"Position cut used for {}\".format(col_name))\n          if basketX[c] < 0:\n            Xi[c,:,:] = xi[:51,:]\n          #TODO: BELOW IS WRONG Original error: pretty sure the below is a relfection for x coordinate, and not a rotation about z axis\n          else:\n            Xi[c,:,:] = xi[50:,:][::-1]\n\n    X_small = np.zeros([Xi.shape[0], *self.image_size, 1])\n\n    for k in range(Xi.shape[0]):\n      X_small[k,:,:,0] = cv2.resize(Xi[k,:,:], self.image_size)\n      X_small[k,:,:,0] = X_small[k,:,:,0]/X_small[k,:,:,0].max()\n      # Mrinal's addition\n      X_small[np.isnan(X_small)] = 0\n      \n    if self.flat:\n      X_small = X_small.reshape(len(df_heatmaps_pandas), np.prod(self.image_size))\n\n    feature_columns = [\"gameId\", \"dividerId\", \"teamId\", \"startWcTime\", \"endWcTime\", \"startGcTime\", \"endGcTime\", \"period\"]\n      \n    return X_small, df_heatmaps_pandas[ feature_columns ]\n  \n  def cleanup_data(self):\n    spark.sql(f\"DROP TABLE {self.train_data_table}\")\n    spark.sql(f\"DROP TABLE {self.test_data_table}\")\n    \n  \n    "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"caba05da-7398-41de-9a11-3fc7bccfecfc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["from random import shuffle\n\nsqlContext.sql(\"SET hive.mapred.supports.subdirectories=true\")\nsqlContext.sql(\"SET mapreduce.input.fileinputformat.input.dir.recursive=true\")\nsqlContext.sql(\"SET spark.sql.execution.arrow.pyspark.enabled=True\")\n\nclass TransferData:\n  def __init__(self, base_path=\"dbfs:/mnt/msft-nba-ml/rolling_courts/\", \n               base_window_length=128, join_window_lengths=[], target_num_partitions=1, games_count=4,\n               desired_train_cases=10000, desired_test_cases=5000):\n    \n    # Caputre the kwargs\n    self.TARGET_NUM_PARTITIONS = target_num_partitions\n    self.base_path = base_path\n    self.base_window_length = base_window_length\n    self.join_window_lengths = join_window_lengths\n    self.desired_train_cases = 10000\n    self.desired_test_cases = 5000\n    \n    # Defing the columns to be used to slice the data\n    self.feature_columns = ['ballPositionHC', 'ballSpeedHC', \n                            'playerPositionHCDefense', 'playerSpeedHCDefense', \n                            'playerPositionHCOffense', 'playerSpeedHCOffense']\n    self.label_columns = ['isPostUp']\n    self.index_columns = ['gameId', 'period', 'possId', 'frameId']\n    self.team_columns = ['teamIdOffense', 'teamIdDefense']\n    self.cv_columns = ['is_test']\n    \n    # Get a list of data directories available to load; limited to the number of games `games_count`\n    self.data_dirs = self.get_data_dirs(games_count)\n    \n    # Load the raw data from those directories\n    self.raw_data, self.base_dataframe = self.load_data(self.data_dirs, self.TARGET_NUM_PARTITIONS * len(self.data_dirs), \n                                                        self.base_window_length, self.base_columns)\n  \n    # Line up the join_window_lengths with the base_window row-by-row for each frameId\n    self.join_all_times()\n    sepa\n    self.get_counts_and_rates()\n  \n  @staticmethod\n  def get_data_dirs_dict(required_windows={'128','64','32','16'}):\n\n    data_dict = {}\n\n    data_dirs = [x.path for x in dbutils.fs.ls('/mnt/msft-nba-ml/rolling_courts/')]\n\n    shuffle(data_dirs)\n\n    for data_dir in data_dirs:\n\n      game_id = data_dir.split('-')[-1][:-1]\n      window_length = data_dir.split('-')[-2]\n\n      if game_id not in data_dict:\n        data_dict[game_id] = {}\n\n      data_dict[game_id][window_length] = data_dir\n\n    return {k:v for k,v in data_dict.items() if set(v.keys()) == required_windows}\n  \n  @classmethod\n  def get_data_dirs(cls, games_count):\n    \n    data_dirs_dict = cls.get_data_dirs_dict()\n    \n    some_data = {k:v for i, (k,v) in enumerate(data_dirs_dict.items()) if i < games_count}\n\n    data_dirs = []\n    for x in some_data.values():\n      data_dirs += list(x.values())\n      \n    return data_dirs\n  \n  @classmethod\n  def load_data(cls, data_dirs, target_num_partitions, base_window_length, base_columns):\n    \n    list_feature = None\n    for data_dir in data_dirs:\n      if list_feature:\n        list_feature = list_feature.union(spark.read.parquet(data_dir).select(list_feature.columns))\n      else:\n        list_feature = spark.read.parquet(data_dir)\n\n    raw_data = cls.add_train_test_label(list_feature)\n        \n    base_dataframe = raw_data.filter(f.col('window_length')==base_window_length).select(base_columns)\n        \n    return raw_data, base_dataframe\n\n  @staticmethod\n  def add_train_test_label(list_feature, test_split=1/3):\n    \n    distinct_game_poss = ( list_feature.select('gameId','possId').distinct()\n                                       .withColumn('is_test', f.rand() > (1-test_split)) )\n\n    return list_feature.join(distinct_game_poss, on=['gameId', 'possId'], how='left')\n  \n  @property\n  def base_columns(self):\n    return self.index_columns + \\\n           self.cv_columns + \\\n           self.team_columns + \\\n           [f.col(x).alias(f\"{x}_w{self.base_window_length}_d0\") for x in self.feature_columns] + \\\n           [f.col(x).alias(f\"{x}_w{self.base_window_length}_d0\") for x in self.label_columns]\n  \n  def get_join_columns(self, join_window_length, delay):\n    \n    return self.index_columns + \\\n           [f.col(x).alias(f\"{x}_w{join_window_length}_d{delay}\") for x in self.feature_columns] + \\\n           [f.col(x).alias(f\"{x}_w{join_window_length}_d{delay}\") for x in self.label_columns]\n  \n  def get_join_dataframe(self, join_window_length, delay):\n    \n    base_alias = f\"df_{self.base_window_length}\"\n    join_alias = f\"df_{join_window_length}\"\n    \n    join_columns = self.get_join_columns(join_window_length, delay)\n    \n    return ( self.raw_data.filter(f.col('window_length')==join_window_length)\n                                    .select(join_columns) )\n    \n  def get_sample_data(self):\n    return \\\n      ( self.base_dataframe.filter(f.col('is_test')==False).sample(self.sample_rate_train).toPandas(),\n        self.base_dataframe.filter(f.col('is_test')==True).sample(self.sample_rate_test).toPandas() )\n    \n  def get_dataset(self):\n    def create_court(x):\n      x = cv2.resize(np.array(x).reshape(51,51), (28,28))\n      x /= x.max() + 10**-9\n      return x.reshape(1,28,28,1)\n\n    df_list_feature_train, df_list_feature_test = self.get_sample_data()\n    \n    train_images = [np.concatenate(df_list_feature_train[feature_column].apply(lambda x: create_court(x)).values, axis=0)\n                    for feature_column in self.all_feature_columns]\n    test_images = [np.concatenate(df_list_feature_test[feature_column].apply(lambda x: create_court(x)).values, axis=0)\n                   for feature_column in self.all_feature_columns]\n\n    train_labels = np.reshape(df_list_feature_train[self.all_label_columns].values, \n                              (len(df_list_feature_train), len(self.all_label_columns)))\n    test_labels = np.reshape(df_list_feature_test[self.all_label_columns].values, \n                             (len(df_list_feature_test), len(self.all_label_columns)))\n\n    train_index = df_list_feature_train[self.index_columns]\n    test_index = df_list_feature_test[self.index_columns]\n\n    ###### TEMP\n\n    train_labels = train_labels[:,[0]].astype('bool')\n    test_labels = test_labels[:,[0]].astype('bool')\n\n    ###### Convert to Tensors for better memory management\n\n    train_labels__tf = tf.convert_to_tensor(train_labels)\n    test_labels__tf = tf.convert_to_tensor(test_labels)\n\n    train_images__tf = [tf.convert_to_tensor(x) for x in train_images]\n    test_images__tf = [tf.convert_to_tensor(x) for x in test_images]\n    \n    return {'train_images': train_images__tf,\n            'test_images': test_images__tf,\n            'train_labels': train_labels__tf,\n            'test_labels': test_labels__tf,\n            'train_index': train_index,\n            'test_index': test_index}\n    \n  def join_all_times(self):\n    \n    base_alias = f\"df_{self.base_window_length}\"\n    for join_window_length in self.join_window_lengths:\n      \n      for delay in range(0,self.base_window_length,join_window_length):\n      \n        join_alias = f\"df_{join_window_length}_{delay}\"\n\n        join_dataframe = self.get_join_dataframe(join_window_length, delay)\n\n        select_join = [f\"{join_alias}.{x}\" for x in join_dataframe.columns if x not in self.index_columns]\n\n        self.base_dataframe = \\\n          ( self.base_dataframe.alias(base_alias)\n             .join(join_dataframe.alias(join_alias),\n                   on=( f.col(f'{base_alias}.gameId') == f.col(f'{join_alias}.gameId') ) & \n                      ( f.col(f'{base_alias}.possId') == f.col(f'{join_alias}.possId') ) &\n                      ( f.col(f'{base_alias}.frameId') == f.col(f'{join_alias}.frameId') - delay ),\n                   how='left')\n             .select(f\"{base_alias}.*\",*select_join))\n        \n    self.clean_up_join()\n        \n  def clean_up_join(self):\n    self.all_feature_columns = [x for x in self.base_dataframe.columns if \"Position\" in x or \"Speed\" in x]\n    self.all_label_columns = [x for x in self.base_dataframe.columns if \"isPostUp\" in x]\n\n    for feature_column in self.all_feature_columns:\n      self.base_dataframe = self.base_dataframe.filter(f.col(feature_column).isNotNull())\n\n    self.base_dataframe.cache()\n    \n  def get_counts_and_rates(self):\n    self.total_samples = self.base_dataframe.count()\n    \n    self.is_test_counts = {x['is_test']: x['count'] for x in \n                           self.base_dataframe.select('is_test').groupBy('is_test').count().collect()}\n\n    self.sample_rate_train = self.desired_train_cases/self.is_test_counts[False]\n    self.sample_rate_test = self.desired_test_cases/self.is_test_counts[True]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8c1cb2e6-7511-4394-854c-41481a9df148"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["if False:\n  model_data = ModelData(\"test_mce\", \"test_mcm\", new_dividers=True)\n  (X_train, X_train_labels), (X_test, X_test_labels) = model_data.get_dataset()\n  model_data.cleanup_data()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d50e8ff8-e060-461d-8995-7839a994a9ce"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"74914ae0-77b4-42e1-a7e8-8a9591d79d71"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"model_data","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2958729778901666}},"nbformat":4,"nbformat_minor":0}